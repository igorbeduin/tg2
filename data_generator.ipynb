{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3QMmr_GtRa7"
   },
   "source": [
    "# Geração do dataset\n",
    "O dataset gerado por este scrip está separado em treino/teste e organizado por classes, pronto para ser utilizado como generator do Tensorflow.\n",
    "Foi criado uma classe Dataset, de onde cada dataset herda uma classe específica. Ex.: o dataset \"covid-chestxray-dataset (<https://github.com/ieee8023/covid-chestxray-dataset>)\" é instanciado pela classe *cohen()*.\n",
    "\n",
    "O pipeline de processamento é:<br>\n",
    "1 - import das bibliotecas<br>\n",
    "2 - instanciação dos objetos de cada dataset<br>\n",
    "3 - Rotina de leitura de cada dataset, aplicando as devidas funções<br>\n",
    "Obs.: nem todos os datasets possuem funções de prefiltragem/posfiltragem. Essas funções foram definidas conforme o processamento feito em <https://github.com/lindawangg/COVID-Net><br>\n",
    "4 - Junção das tabelas de cada ds em uma só (com excessão do RSNA)<br>\n",
    "5.1a - Filtragem das classes de interesse na tabela de imagens<br>\n",
    "5.1b - Separação de imagens específicas para teste, conforme <https://github.com/lindawangg/COVID-Net><br>\n",
    "5.2a - Filtragem das classes de interesse na tabela do RSNA<br>\n",
    "5.2b - Aplica *split* no dataset RSNA<br>\n",
    "6 - Junta as tabelas de treino e teste<br>\n",
    "7 - Monta o dataset no path destino, copiando as imagens que já estão em formato de leitura e escrevendo as imagens em ```.dcm```<br>\n",
    "<br>\n",
    "Obs.: as estapas 3 e 7 podem demorar consideravelmente devido ao dataset RSNA que possui mais de 15k imagens. A fim de verificar a validade do script recomenda-se rodá-lo sem este dataset.<br>\n",
    "<br>\n",
    "As tables ou tabelas referidas nesse script são listas de dicionário do tipo \\[{\"path\": target_path, \"filename\": filename, \"class\": finding, \"url\": url, \"id\": patientid}\\], onde:<br>\n",
    "- target_path = localização da imagem dentro do diretorio do dataset;<br>\n",
    "- filename = nome do arquivo, presente no dataset;<br>\n",
    "- class = classe de classificação da imagem. Ex.: Normal, COVID-19, etc;<br>\n",
    "- url = URL da imagem, usado para detecção de imagens presentes simultaneamente em dois ou mais datasets. Se não há \"url\" no dataset, o valor None é preenchido na tabela;<br>\n",
    "- patientid = utilizado para busca rapida de alguns paciente. Se não há \"patientid\" no dataset, o nome do arquivo sem extensão é utilizado.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26942,
     "status": "ok",
     "timestamp": 1611717811762,
     "user": {
      "displayName": "Igor Beduin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicrLX4A8XIurRrs5tUPFTs_mZ6LzjddQeBQkKTng=s64",
      "userId": "12542818864135131012"
     },
     "user_tz": 180
    },
    "id": "3YI85KgPtjoj",
    "outputId": "0427ee43-7edc-406e-8988-5ad5fca223f3"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 137798,
     "status": "ok",
     "timestamp": 1611718178618,
     "user": {
      "displayName": "Igor Beduin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicrLX4A8XIurRrs5tUPFTs_mZ6LzjddQeBQkKTng=s64",
      "userId": "12542818864135131012"
     },
     "user_tz": 180
    },
    "id": "MBXPXP-st2Mo",
    "outputId": "5c76af88-a6d5-4ecd-803e-fee94d402755"
   },
   "outputs": [],
   "source": [
    "# installl requirements on google colab\n",
    "!pip install -r drive/MyDrive/TG/tg2_COVIDNet/requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcfo9r7atRbN"
   },
   "source": [
    "## IMPORT DA LIBS E FUNÇÕES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txkoq6GitRbP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random \n",
    "import pydicom as dicom\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cx2oQsxStRbR"
   },
   "outputs": [],
   "source": [
    "from datasets import rsna, actualmed, cohen, fig1, sirm\n",
    "from ds_utils import filter_table, split_table, table_info, remove_dupl_field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPeVZeGCtRbT"
   },
   "source": [
    "## CONSTROI OS OBJ DE CADA DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-M_d4GzqtRbU"
   },
   "outputs": [],
   "source": [
    "# datasets_path = os.path.join(os.getcwd(), \"datasets\")\n",
    "datasets_path = \"/Users/igorbeduin/Google Drive (beduinigor@gmail.com)/TG/datasets\"\n",
    "\n",
    "cohen = cohen(datasets_path)\n",
    "rsna = rsna(datasets_path)\n",
    "actualmed = actualmed(datasets_path)\n",
    "fig1 = fig1(datasets_path)\n",
    "sirm = sirm(datasets_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzDtxm8KtRbU"
   },
   "source": [
    "## LE CADA DS E CONSTROI SUA TABELA APLICANDO AS FUNCOES NECESSARIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3YG1D9o6tRbV"
   },
   "outputs": [],
   "source": [
    "datasets = [cohen, actualmed, fig1, sirm, rsna]\n",
    "for ds in datasets:\n",
    "    ds.read()\n",
    "    ds.prefilter()\n",
    "    ds.mount_table()\n",
    "    ds.postfilter()\n",
    "    ds.mount_count_table()\n",
    "    if ds.__name__ is sirm.__name__:\n",
    "        remove_dupl_field(sirm, cohen, \"url\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UWyaQaDtRbV"
   },
   "source": [
    "## JUNTA AS TABELAS EM UMA SÓ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GJvksodtRbX"
   },
   "outputs": [],
   "source": [
    "target_ds = [cohen, actualmed, fig1, sirm]\n",
    "file_table = []\n",
    "for ds in target_ds:\n",
    "    print(f\"Dataset: {ds.__name__.upper()}\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(f\"Imagens: {ds.count}\")\n",
    "    print(f\"Contagem de cada classe por dataset: {ds.count_table}\\n\")\n",
    "    file_table += ds.table\n",
    "\n",
    "print(f\"Total de imagens: {len(file_table)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vm91D7QJtRbX"
   },
   "source": [
    "## FILTRA A TABELA PARA USO APENAS DAS CLASSES DE INTERESSE\n",
    "Se general_case=\"remove\":<br>\n",
    "    - Se a classe da imagen não está em mapping, a imagem é removida da table<br>\n",
    "Se general_case=\"subst\":<br>\n",
    "    - Se a classe da imagen não está em mapping, a classe da imagem é modificada para o valor em \"std_subst\"<br>\n",
    "        Para este caso é possível passar uma lista ```remove_classes```, assim a classe não presente em mapping será substituída no caso padrão mas será removida da table se estiver presente na lista. <br>\n",
    "        Ex.:<br>\n",
    "        - class = \"blabla\" será atribuída o valor de mapping[\"std_subst\"]<br>\n",
    "        - class = \"todo\" terá a imagem removida da tabela<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDep0J75tRbY"
   },
   "outputs": [],
   "source": [
    "mapping = {\"COVID-19\": \"COVID-19\",\n",
    "           \"COVID-19, ARDS\": \"COVID-19\",\n",
    "           \"Normal\": \"Normal\",\n",
    "           \"Pneumonia\": \"Pneumonia\", # OBS.: Linda ignora essa classe\n",
    "           \"SARS\": \"Pneumonia\",\n",
    "           \"MERS\": \"Pneumonia\",\n",
    "           \"Streptococcus\": \"Pneumonia\",\n",
    "           \"Klebsiella\": \"Pneumonia\",\n",
    "           \"Chlamydophila\": \"Pneumonia\",\n",
    "           \"Legionella\": \"Pneumonia\",\n",
    "           \"Lung Opacity\": \"Pneumonia\",\n",
    "           \"1\": \"Pneumonia\",\n",
    "           \"std_subst\": \"Non-COVID\"}\n",
    "# remove_classes = [\"todo\", \"nan\", \"Unknown\"]\n",
    "\n",
    "filtered_table = filter_table(file_table, mapping, general_case=\"remove\")\n",
    "table_info(filtered_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXUO0ypjtRbZ"
   },
   "source": [
    "## SEPARAÇÃO DE TESTES PARA COHEN, FIG1, ACTUALMED E SIRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-VwTvIxtRbZ"
   },
   "outputs": [],
   "source": [
    "test_patients = {\"Pneumonia\": ['8', '31'],\n",
    "                 \"COVID-19\": ['19', '20', '36', '42', '86', \n",
    "                              '94', '97', '117', '132', \n",
    "                              '138', '144', '150', '163', '169', '174', '175', '179', '190', '191',\n",
    "                              'COVID-00024', 'COVID-00025', 'COVID-00026', 'COVID-00027', 'COVID-00029',\n",
    "                              'COVID-00030', 'COVID-00032', 'COVID-00033', 'COVID-00035', 'COVID-00036',\n",
    "                              'COVID-00037', 'COVID-00038',\n",
    "                              'ANON24', 'ANON45', 'ANON126', 'ANON106', 'ANON67',\n",
    "                              'ANON153', 'ANON135', 'ANON44', 'ANON29', 'ANON201', \n",
    "                              'ANON191', 'ANON234', 'ANON110', 'ANON112', 'ANON73', \n",
    "                              'ANON220', 'ANON189', 'ANON30', 'ANON53', 'ANON46',\n",
    "                              'ANON218', 'ANON240', 'ANON100', 'ANON237', 'ANON158',\n",
    "                              'ANON174', 'ANON19', 'ANON195',\n",
    "                              'COVID-19(119)', 'COVID-19(87)', 'COVID-19(70)', 'COVID-19(94)', \n",
    "                              'COVID-19(215)', 'COVID-19(77)', 'COVID-19(213)', 'COVID-19(81)', \n",
    "                              'COVID-19(216)', 'COVID-19(72)', 'COVID-19(106)', 'COVID-19(131)', \n",
    "                              'COVID-19(107)', 'COVID-19(116)', 'COVID-19(95)', 'COVID-19(214)', \n",
    "                              'COVID-19(129)']}\n",
    "\n",
    "test_table = []\n",
    "train_table = []\n",
    "for row in filtered_table:\n",
    "    if row[\"class\"] in test_patients and row[\"id\"] in test_patients[row[\"class\"]]:\n",
    "        test_table.append(row)\n",
    "    else:\n",
    "        train_table.append(row)\n",
    "    \n",
    "print(f\"\\nTRAIN:\\n-------------------\")\n",
    "table_info(train_table)\n",
    "print(f\"\\nTEST:\\n-------------------\")\n",
    "table_info(test_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64NCOWBhtRba"
   },
   "source": [
    "## FILTRAGEM DAS CLASSES DE INTERESSE DO RSNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "InWMuo_ZtRbb"
   },
   "outputs": [],
   "source": [
    "rsna_filtered_table = filter_table(rsna.table, mapping, general_case=\"remove\")\n",
    "table_info(rsna_filtered_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K71Np5GPtRbb"
   },
   "source": [
    "## SEPARAÇÃO DE TESTES RSNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cknsyRSGtRbc"
   },
   "outputs": [],
   "source": [
    "split = 0.2\n",
    "rsna_train, rsna_test = split_table(rsna_filtered_table, split)\n",
    "print(f\"\\nTRAIN:\\n-------------------\")\n",
    "table_info(rsna_train)\n",
    "print(f\"\\nTEST:\\n-------------------\")\n",
    "table_info(rsna_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cf1NECVRtRbk"
   },
   "source": [
    "## JUNTA AS TABLES DE TESTE E TREINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SBRi3h_tRbk"
   },
   "outputs": [],
   "source": [
    "from ds_utils import remove_duplicated\n",
    "\n",
    "train_table += rsna_train\n",
    "test_table += rsna_test\n",
    "\n",
    "print(f\"\\nTRAIN:\\n-------------------\")\n",
    "table_info(train_table)\n",
    "print(f\"\\nTEST:\\n-------------------\")\n",
    "table_info(test_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDgr2SG_tRbl"
   },
   "source": [
    "# MONTA O DATASET COPIANDO OS ARQUIVOS DA TABLE (SEPARADOS POR CLASSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "executionInfo": {
     "elapsed": 747,
     "status": "error",
     "timestamp": 1611645664184,
     "user": {
      "displayName": "Igor Beduin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicrLX4A8XIurRrs5tUPFTs_mZ6LzjddQeBQkKTng=s64",
      "userId": "12542818864135131012"
     },
     "user_tz": 180
    },
    "id": "GOkuqCOGtRbl",
    "outputId": "666778ee-05f8-4c87-c2bd-d980e1504072"
   },
   "outputs": [],
   "source": [
    "from ds_utils import mount_dataset\n",
    "\n",
    "mounted_dataset_path = \"../target_dataset\"\n",
    "if not os.path.isdir(mounted_dataset_path):\n",
    "    os.mkdir(mounted_dataset_path)\n",
    "train_path = os.path.join(mounted_dataset_path, \"train\")\n",
    "test_path = os.path.join(mounted_dataset_path, \"test\")\n",
    "\n",
    "print(f\"\\nTRAIN:\\n-------------------\")\n",
    "mount_dataset(train_path, train_table)\n",
    "print(f\"\\nTEST:\\n-------------------\")\n",
    "mount_dataset(test_path, test_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "div7_rpUtRbo"
   },
   "source": [
    "## TREINAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 788,
     "status": "ok",
     "timestamp": 1611718204740,
     "user": {
      "displayName": "Igor Beduin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicrLX4A8XIurRrs5tUPFTs_mZ6LzjddQeBQkKTng=s64",
      "userId": "12542818864135131012"
     },
     "user_tz": 180
    },
    "id": "Zmh9vQCjtRbp"
   },
   "outputs": [],
   "source": [
    "mounted_dataset_path = '/home/beduinigor/target_dataset'\n",
    "#mounted_dataset_path = \"/content/drive/MyDrive/TG/tg2_COVIDNet/target_dataset\"\n",
    "#mounted_dataset_path = \"./target_dataset\"\n",
    "image_size = (240, 240)\n",
    "total_training_images = 12460\n",
    "total_test_images = 3080\n",
    "batch_size = 32\n",
    "train_max_batches = int(total_training_images/batch_size)\n",
    "test_max_batches = int(total_test_images/batch_size)\n",
    "color_mode = \"grayscale\"\n",
    "class_mode = \"categorical\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tc69CY0QtRbp"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "train_datagen = train_datagen.flow_from_directory(\n",
    "    os.path.join(mounted_dataset_path, \"train\"),\n",
    "    shuffle=True,\n",
    "    target_size=image_size,\n",
    "    color_mode=color_mode,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_datagen = test_datagen.flow_from_directory(\n",
    "    os.path.join(mounted_dataset_path, \"test\"),\n",
    "    shuffle=True,\n",
    "    target_size=image_size,\n",
    "    color_mode=color_mode,\n",
    "    batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISaEaxNitRbr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "print(\"Creating training array: \")\n",
    "for i in range(train_max_batches):\n",
    "    print(f\"  Batch: {i}\")\n",
    "    batch = train_datagen.next()\n",
    "    x_train.extend(batch[0])\n",
    "    y_train.extend(batch[1])\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "print(\"\\nCreating test array:\")\n",
    "for i in range(test_max_batches):\n",
    "    print(f\"  Batch: {i}\")\n",
    "    batch = test_datagen.next()\n",
    "    x_test.extend(batch[0])\n",
    "    y_test.extend(batch[1])\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oS9DHNV3jU9H"
   },
   "source": [
    "## Save train and test numpy dataset array to disk\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3OG8eceqjU9H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from numpy import save\n",
    "\n",
    "# ds_arrays_path = '/content/drive/MyDrive/TG/dataset_arrays'\n",
    "ds_arrays_path = '/home/beduinigor/dataset_arrays'\n",
    "\n",
    "save(os.path.join(ds_arrays_path, 'x_train_data.npy'), x_train)\n",
    "save(os.path.join(ds_arrays_path, 'y_train_data.npy'), y_train)\n",
    "\n",
    "save(os.path.join(ds_arrays_path, 'x_test_data.npy'), x_test)\n",
    "save(os.path.join(ds_arrays_path, 'y_test_data.npy'), y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reju83mkkeEV"
   },
   "source": [
    "## Load train and test numpy dataset array to disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 99587,
     "status": "ok",
     "timestamp": 1611718312517,
     "user": {
      "displayName": "Igor Beduin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicrLX4A8XIurRrs5tUPFTs_mZ6LzjddQeBQkKTng=s64",
      "userId": "12542818864135131012"
     },
     "user_tz": 180
    },
    "id": "Luan4zu9jU9H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from numpy import load\n",
    "\n",
    "# ds_arrays_path = '/content/drive/MyDrive/TG/dataset_arrays'\n",
    "ds_arrays_path = '/home/beduinigor/dataset_arrays'\n",
    "\n",
    "x_train = load(os.path.join(ds_arrays_path,'x_train_data.npy'))\n",
    "y_train = load(os.path.join(ds_arrays_path,'y_train_data.npy'))\n",
    "x_test = load(os.path.join(ds_arrays_path,'x_test_data.npy'))\n",
    "y_test = load(os.path.join(ds_arrays_path,'y_test_data.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 98124,
     "status": "ok",
     "timestamp": 1611718312520,
     "user": {
      "displayName": "Igor Beduin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicrLX4A8XIurRrs5tUPFTs_mZ6LzjddQeBQkKTng=s64",
      "userId": "12542818864135131012"
     },
     "user_tz": 180
    },
    "id": "ojbQgsUStRbs",
    "outputId": "cc313ccd-2273-4389-ed44-52878d068647"
   },
   "outputs": [],
   "source": [
    "print(\"TRAIN\\n----------\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"\\nTEST\\n----------\")\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 842,
     "status": "ok",
     "timestamp": 1611718336178,
     "user": {
      "displayName": "Igor Beduin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicrLX4A8XIurRrs5tUPFTs_mZ6LzjddQeBQkKTng=s64",
      "userId": "12542818864135131012"
     },
     "user_tz": 180
    },
    "id": "5dIrlFgZtRbt"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# tb_log_dir = \"/Users/igorbeduin/Google Drive (beduinigor@gmail.com)/TG/tensorboard\"\n",
    "tb_log_dir = '/home/beduinigor/training/tensorboard'\n",
    "\n",
    "checkpoint_path = \"/home/beduinigor/tg2_COVIDNet/checkpoints/weights.epoch:{epoch:02d}-acc:{accuracy:.2f}.h5\"\n",
    "checkpoint_epochs = 7000\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor=\"val_loss\",\n",
    "                    min_delta=0,\n",
    "                    patience=20,\n",
    "                    verbose=1,\n",
    "                    mode=\"auto\",\n",
    "                    baseline=None,\n",
    "                    restore_best_weights=True)\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "                    log_dir=tb_log_dir,\n",
    "                    histogram_freq=0,\n",
    "                    write_graph=True,\n",
    "                    write_images=False,\n",
    "                    update_freq=\"epoch\",\n",
    "                    profile_batch=100000000000,\n",
    "                    embeddings_freq=0,\n",
    "                    embeddings_metadata=None)\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "                    checkpoint_path,\n",
    "                    monitor=\"val_loss\",\n",
    "                    verbose=1,\n",
    "                    save_best_only=False,\n",
    "                    save_weights_only=False,\n",
    "                    mode=\"auto\",\n",
    "                    save_freq=checkpoint_epochs,\n",
    "                    options=None)\n",
    "\n",
    "callbacks = [tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okAEcA3SMFT4"
   },
   "source": [
    "### Searching on resnet models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "executionInfo": {
     "elapsed": 16946,
     "status": "error",
     "timestamp": 1611718442414,
     "user": {
      "displayName": "Igor Beduin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicrLX4A8XIurRrs5tUPFTs_mZ6LzjddQeBQkKTng=s64",
      "userId": "12542818864135131012"
     },
     "user_tz": 180
    },
    "id": "CD3LqeLktRbu",
    "outputId": "fc504b7a-1d48-41a2-89a8-910c93003b8b"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import autokeras as ak\n",
    "\n",
    "# model_path = \"/content/drive/MyDrive/TG/training/models\"\n",
    "model_path = \"/home/beduinigor/training/models\"\n",
    "\n",
    "input_node = ak.ImageInput()\n",
    "output_node = ak.ImageBlock(\n",
    "    # Only search ResNet architectures.\n",
    "    block_type=\"resnet\",\n",
    "    # Normalize the dataset.\n",
    "    normalize=False,\n",
    "    # Do not do data augmentation.\n",
    "    augment=False,\n",
    "    )(input_node)\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "\n",
    "model = ak.AutoModel(\n",
    "    inputs=input_node, \n",
    "    outputs=output_node,\n",
    "    directory=model_path,\n",
    "    overwrite=False,\n",
    "    max_trials=100)\n",
    "\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=callbacks, \n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    verbose=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ptu_yzqMFT6"
   },
   "source": [
    "### Searching on every classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 27220,
     "status": "error",
     "timestamp": 1611718366370,
     "user": {
      "displayName": "Igor Beduin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicrLX4A8XIurRrs5tUPFTs_mZ6LzjddQeBQkKTng=s64",
      "userId": "12542818864135131012"
     },
     "user_tz": 180
    },
    "id": "PJAWeU3lMFT9",
    "outputId": "5cbf4793-89cf-4aaf-9306-ceaa4c34e77c"
   },
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "\n",
    "# model_path = \"/content/drive/MyDrive/TG/training/models\"\n",
    "model_path = \"/home/beduinigor/training/models\"\n",
    "\n",
    "model = ak.ImageClassifier(\n",
    "    num_classes=3,\n",
    "    overwrite=False,\n",
    "    directory=model_path,\n",
    "    max_trials=100)\n",
    "\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=callbacks, \n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cozsE4g2tRbv"
   },
   "outputs": [],
   "source": [
    "trained_model = model.export_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zx1c_rXUtRbw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "finalmodel_dir = '/home/beduinigor/training/models'\n",
    "\n",
    "trained_model.save(os.path.join(finalmodel_dir, \"final_model.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-gim3JptRbw"
   },
   "source": [
    "## LEITURA DE PESOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3NP1Zu-tRbw"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "#checkpoints_path = \"/home/beduinigor/tg2_COVIDNet/checkpoints\"\n",
    "auto_model_path = \"/media/training/covidnet/auto_model\"\n",
    "best_model_path = \"/media/training/covidnet/checkpoints/final_model.h5\"\n",
    "\n",
    "loaded_model = load_model(best_model_path)\n",
    "print(loaded_model.evaluate(x_test, y_test, batch_size=batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2l8Hy5btRb9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "hcfo9r7atRbN",
    "lPeVZeGCtRbT",
    "DzDtxm8KtRbU",
    "0UWyaQaDtRbV",
    "Vm91D7QJtRbX",
    "RXUO0ypjtRbZ",
    "64NCOWBhtRba",
    "K71Np5GPtRbb",
    "Cf1NECVRtRbk"
   ],
   "name": "data_generator.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
