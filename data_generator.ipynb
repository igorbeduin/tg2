{
 "cells": [
  {
   "source": [
    "# Geração do dataset\n",
    "O dataset gerado por este scrip está separado em treino/teste e organizado por classes, pronto para ser utilizado como generator do Tensorflow.\n",
    "Foi criado uma classe Dataset, de onde cada dataset herda uma classe específica. Ex.: o dataset \"covid-chestxray-dataset (<https://github.com/ieee8023/covid-chestxray-dataset>)\" é instanciado pela classe *cohen()*.\n",
    "\n",
    "O pipeline de processamento é:<br>\n",
    "1 - import das bibliotecas<br>\n",
    "2 - instanciação dos objetos de cada dataset<br>\n",
    "3 - Rotina de leitura de cada dataset, aplicando as devidas funções<br>\n",
    "Obs.: nem todos os datasets possuem funções de prefiltragem/posfiltragem. Essas funções foram definidas conforme o processamento feito em <https://github.com/lindawangg/COVID-Net><br>\n",
    "4 - Junção das tabelas de cada ds em uma só (com excessão do RSNA)<br>\n",
    "5.1a - Filtragem das classes de interesse na tabela de imagens<br>\n",
    "5.1b - Separação de imagens específicas para teste, conforme <https://github.com/lindawangg/COVID-Net><br>\n",
    "5.2a - Filtragem das classes de interesse na tabela do RSNA<br>\n",
    "5.2b - Aplica *split* no dataset RSNA<br>\n",
    "6 - Junta as tabelas de treino e teste<br>\n",
    "7 - Monta o dataset no path destino, copiando as imagens que já estão em formato de leitura e escrevendo as imagens em ```.dcm```<br>\n",
    "<br>\n",
    "Obs.: as estapas 3 e 7 podem demorar consideravelmente devido ao dataset RSNA que possui mais de 15k imagens. A fim de verificar a validade do script recomenda-se rodá-lo sem este dataset.<br>\n",
    "<br>\n",
    "As tables ou tabelas referidas nesse script são listas de dicionário do tipo \\[{\"path\": target_path, \"filename\": filename, \"class\": finding, \"url\": url, \"id\": patientid}\\], onde:<br>\n",
    "- target_path = localização da imagem dentro do diretorio do dataset;<br>\n",
    "- filename = nome do arquivo, presente no dataset;<br>\n",
    "- class = classe de classificação da imagem. Ex.: Normal, COVID-19, etc;<br>\n",
    "- url = URL da imagem, usado para detecção de imagens presentes simultaneamente em dois ou mais datasets. Se não há \"url\" no dataset, o valor None é preenchido na tabela;<br>\n",
    "- patientid = utilizado para busca rapida de alguns paciente. Se não há \"patientid\" no dataset, o nome do arquivo sem extensão é utilizado.<br>\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## IMPORT DA LIBS E FUNÇÕES"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random \n",
    "import pydicom as dicom\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import rsna, actualmed, cohen, fig1, sirm\n",
    "from ds_utils import filter_table, split_table, table_info, remove_dupl_field"
   ]
  },
  {
   "source": [
    "## CONSTROI OS OBJ DE CADA DS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = os.path.join(os.getcwd(), \"datasets\")\n",
    "\n",
    "cohen = cohen(datasets_path)\n",
    "rsna = rsna(datasets_path)\n",
    "actualmed = actualmed(datasets_path)\n",
    "fig1 = fig1(datasets_path)\n",
    "sirm = sirm(datasets_path)"
   ]
  },
  {
   "source": [
    "## LE CADA DS E CONSTROI SUA TABELA APLICANDO AS FUNCOES NECESSARIAS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [cohen, actualmed, fig1, sirm, rsna]\n",
    "for ds in datasets:\n",
    "    ds.read()\n",
    "    ds.prefilter()\n",
    "    ds.mount_table()\n",
    "    ds.postfilter()\n",
    "    ds.mount_count_table()\n",
    "    if ds.__name__ is sirm.__name__:\n",
    "        remove_dupl_field(sirm, cohen, \"url\")"
   ]
  },
  {
   "source": [
    "## JUNTA AS TABELAS EM UMA SÓ"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset: COHEN\n-----------------------------------------\nImagens: 763\nContagem de cada classe por dataset: {'COVID-19': 456, 'ARDS': 5, 'SARS': 16, 'Pneumocystis': 24, 'Streptococcus': 18, 'No Finding': 17, 'Chlamydophila': 1, 'E.Coli': 4, 'COVID-19, ARDS': 12, 'Klebsiella': 9, 'Legionella': 7, 'Unknown': 1, 'Pneumonia': 17, 'Lipoid': 8, 'Varicella': 5, 'Bacterial': 2, 'Mycoplasma Bacterial Pneumonia': 5, 'Influenza': 3, 'Cryptogenic Organizing Pneumonia': 10, 'Lobar Pneumonia': 5, 'Multilobar Pneumonia': 3, 'Organizing Pneumonia': 1, 'Eosinophilic Pneumonia': 2, 'Unusual Interstitial Pneumonia': 1, 'Lymphocytic Interstitial Pneumonia': 2, 'Desquamative Interstitial Pneumonia': 1, 'todo': 83, 'Spinal Tuberculosis': 1, 'Swine-Origin Influenza A (H1N1) Viral Pneumonia': 1, 'Tuberculosis': 10, 'Invasive Aspergillosis': 1, 'Herpes pneumonia': 2, 'Herpes pneumonia, ARDS': 1, 'Accelerated Phase Usual Interstitial Pneumonia': 2, 'Round pneumonia': 1, 'Lymphocytic interstitial pneumonia': 1, 'Allergic bronchopulmonary aspergillosis ': 1, 'Cryptogenic organising pneumonia': 2, 'Chronic eosinophilic pneumonia': 3, 'Aspiration pneumonia': 1, 'Nocardia': 4, 'MERS-CoV': 10, 'Eosinophilic pneumonia': 2, 'Cryptogenic organizing pneumonia': 1, 'MRSA': 1}\n\nDataset: ACTUALMED\n-----------------------------------------\nImagens: 238\nContagem de cada classe por dataset: {nan: 53, 'No finding': 127, 'COVID-19': 58}\n\nDataset: FIG1\n-----------------------------------------\nImagens: 55\nContagem de cada classe por dataset: {'COVID-19': 35, nan: 15, 'No finding': 3, 'Pneumonia': 2}\n\nDataset: SIRM\n-----------------------------------------\nImagens: 46\nContagem de cada classe por dataset: {'COVID-19': 46}\n\nTotal de imagens: 1102\n"
     ]
    }
   ],
   "source": [
    "target_ds = [cohen, actualmed, fig1, sirm]\n",
    "file_table = []\n",
    "for ds in target_ds:\n",
    "    print(f\"Dataset: {ds.__name__.upper()}\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(f\"Imagens: {ds.count}\")\n",
    "    print(f\"Contagem de cada classe por dataset: {ds.count_table}\\n\")\n",
    "    file_table += ds.table\n",
    "\n",
    "print(f\"Total de imagens: {len(file_table)}\")"
   ]
  },
  {
   "source": [
    "## FILTRA A TABELA PARA USO APENAS DAS CLASSES DE INTERESSE\n",
    "Se general_case=\"remove\":<br>\n",
    "    - Se a classe da imagen não está em mapping, a imagem é removida da table<br>\n",
    "Se general_case=\"subst\":<br>\n",
    "    - Se a classe da imagen não está em mapping, a classe da imagem é modificada para o valor em \"std_subst\"<br>\n",
    "        Para este caso é possível passar uma lista ```remove_classes```, assim a classe não presente em mapping será substituída no caso padrão mas será removida da table se estiver presente na lista. <br>\n",
    "        Ex.:<br>\n",
    "        - class = \"blabla\" será atribuída o valor de mapping[\"std_subst\"]<br>\n",
    "        - class = \"todo\" terá a imagem removida da tabela<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "mapping = {\"COVID-19\": \"COVID-19\",\n",
    "           \"COVID-19, ARDS\": \"COVID-19\",\n",
    "           \"Normal\": \"Normal\",\n",
    "           \"Pneumonia\": \"Pneumonia\", # OBS.: Linda ignora essa classe\n",
    "           \"SARS\": \"Pneumonia\",\n",
    "           \"MERS\": \"Pneumonia\",\n",
    "           \"Streptococcus\": \"Pneumonia\",\n",
    "           \"Klebsiella\": \"Pneumonia\",\n",
    "           \"Chlamydophila\": \"Pneumonia\",\n",
    "           \"Legionella\": \"Pneumonia\",\n",
    "           \"Lung Opacity\": \"Pneumonia\",\n",
    "           \"1\": \"Pneumonia\",\n",
    "           \"std_subst\": \"Non-COVID\"}\n",
    "# remove_classes = [\"todo\", \"nan\", \"Unknown\"]\n",
    "\n",
    "filtered_table = filter_table(file_table, mapping, general_case=\"remove\")\n",
    "table_info(filtered_table)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total de imagens: 677\nContagem de cada classe por dataset: {'COVID-19': 607, 'Pneumonia': 70}\n"
     ]
    }
   ]
  },
  {
   "source": [
    "## SEPARAÇÃO DE TESTES PARA COHEN, FIG1, ACTUALMED E SIRM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "test_patients = {\"Pneumonia\": ['8', '31'],\n",
    "                 \"COVID-19\": ['19', '20', '36', '42', '86', \n",
    "                              '94', '97', '117', '132', \n",
    "                              '138', '144', '150', '163', '169', '174', '175', '179', '190', '191',\n",
    "                              'COVID-00024', 'COVID-00025', 'COVID-00026', 'COVID-00027', 'COVID-00029',\n",
    "                              'COVID-00030', 'COVID-00032', 'COVID-00033', 'COVID-00035', 'COVID-00036',\n",
    "                              'COVID-00037', 'COVID-00038',\n",
    "                              'ANON24', 'ANON45', 'ANON126', 'ANON106', 'ANON67',\n",
    "                              'ANON153', 'ANON135', 'ANON44', 'ANON29', 'ANON201', \n",
    "                              'ANON191', 'ANON234', 'ANON110', 'ANON112', 'ANON73', \n",
    "                              'ANON220', 'ANON189', 'ANON30', 'ANON53', 'ANON46',\n",
    "                              'ANON218', 'ANON240', 'ANON100', 'ANON237', 'ANON158',\n",
    "                              'ANON174', 'ANON19', 'ANON195',\n",
    "                              'COVID-19(119)', 'COVID-19(87)', 'COVID-19(70)', 'COVID-19(94)', \n",
    "                              'COVID-19(215)', 'COVID-19(77)', 'COVID-19(213)', 'COVID-19(81)', \n",
    "                              'COVID-19(216)', 'COVID-19(72)', 'COVID-19(106)', 'COVID-19(131)', \n",
    "                              'COVID-19(107)', 'COVID-19(116)', 'COVID-19(95)', 'COVID-19(214)', \n",
    "                              'COVID-19(129)']}\n",
    "\n",
    "test_table = []\n",
    "train_table = []\n",
    "for row in filtered_table:\n",
    "    if row[\"class\"] in test_patients and row[\"id\"] in test_patients[row[\"class\"]]:\n",
    "        test_table.append(row)\n",
    "    else:\n",
    "        train_table.append(row)\n",
    "    \n",
    "print(f\"\\nTRAIN:\\n-------------------\")\n",
    "table_info(train_table)\n",
    "print(f\"\\nTEST:\\n-------------------\")\n",
    "table_info(test_table)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nTRAIN:\n-------------------\nTotal de imagens: 569\nContagem de cada classe por dataset: {'COVID-19': 504, 'Pneumonia': 65}\n\nTEST:\n-------------------\nTotal de imagens: 108\nContagem de cada classe por dataset: {'Pneumonia': 5, 'COVID-19': 103}\n"
     ]
    }
   ]
  },
  {
   "source": [
    "## FILTRAGEM DAS CLASSES DE INTERESSE DO RSNA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total de imagens: 18406\nContagem de cada classe por dataset: {'Normal': 8851, 'Pneumonia': 9555}\n"
     ]
    }
   ],
   "source": [
    "rsna_filtered_table = filter_table(rsna.table, mapping, general_case=\"remove\")\n",
    "table_info(rsna_filtered_table)"
   ]
  },
  {
   "source": [
    "## SEPARAÇÃO DE TESTES RSNA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nTRAIN:\n-------------------\nTotal de imagens: 14725\nContagem de cada classe por dataset: {'Pneumonia': 7674, 'Normal': 7051}\n\nTEST:\n-------------------\nTotal de imagens: 3681\nContagem de cada classe por dataset: {'Pneumonia': 1881, 'Normal': 1800}\n"
     ]
    }
   ],
   "source": [
    "split = 0.2\n",
    "rsna_train, rsna_test = split_table(rsna_filtered_table, split)\n",
    "print(f\"\\nTRAIN:\\n-------------------\")\n",
    "table_info(rsna_train)\n",
    "print(f\"\\nTEST:\\n-------------------\")\n",
    "table_info(rsna_test)"
   ]
  },
  {
   "source": [
    "## JUNTA AS TABLES DE TESTE E TREINO"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "train_table += rsna_train\n",
    "test_table += rsna_test\n",
    "#train_table = rsna_train\n",
    "#test_table = rsna_test\n",
    "\n",
    "print(f\"\\nTRAIN:\\n-------------------\")\n",
    "table_info(train_table)\n",
    "print(f\"\\nTEST:\\n-------------------\")\n",
    "table_info(test_table)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nTRAIN:\n-------------------\nTotal de imagens: 15294\nContagem de cada classe por dataset: {'COVID-19': 504, 'Pneumonia': 7739, 'Normal': 7051}\n\nTEST:\n-------------------\nTotal de imagens: 3789\nContagem de cada classe por dataset: {'Pneumonia': 1886, 'COVID-19': 103, 'Normal': 1800}\n"
     ]
    }
   ]
  },
  {
   "source": [
    "## MONTA O DATASET COPIANDO OS ARQUIVOS DA TABLE (SEPARADOS POR CLASSE)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from ds_utils import mount_dataset\n",
    "\n",
    "mounted_dataset_path = \"./not_sync/target_dataset\"\n",
    "if not os.path.isdir(mounted_dataset_path):\n",
    "    os.mkdir(mounted_dataset_path)\n",
    "train_path = os.path.join(mounted_dataset_path, \"train\")\n",
    "test_path = os.path.join(mounted_dataset_path, \"test\")\n",
    "\n",
    "print(f\"\\nTRAIN:\\n-------------------\")\n",
    "mount_dataset(train_path, train_table)\n",
    "print(f\"\\nTEST:\\n-------------------\")\n",
    "mount_dataset(test_path, test_table)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "TRAIN:\n",
      "-------------------\n",
      "15294 imagens escritas no dataset.\n",
      "\n",
      "TEST:\n",
      "-------------------\n",
      "3789 imagens escritas no dataset.\n"
     ]
    }
   ]
  },
  {
   "source": [
    "VERIFY COPIED FILES"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16683\n"
     ]
    }
   ],
   "source": [
    "verification_list = []\n",
    "for root, dirs, files in os.walk(mounted_dataset_path):\n",
    "    for f in files:\n",
    "        verification_list.append(f)\n",
    "print(len(verification_list))"
   ]
  },
  {
   "source": [
    "TRAINING FEATURES"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (150, 150)\n",
    "batch_size = 32\n",
    "max_batches = 10\n",
    "n_features = 1\n",
    "color_mode = \"grayscale\"\n",
    "class_mode = \"categorical\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 13019 images belonging to 3 classes.\n",
      "Found 3664 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "train_datagen = train_datagen.flow_from_directory(\n",
    "    os.path.join(mounted_dataset_path, \"train\"),\n",
    "    shuffle=True,\n",
    "    target_size=image_size,\n",
    "    color_mode=color_mode,\n",
    "    batch_size=batch_size)\n",
    "test_datagen = test_datagen.flow_from_directory(\n",
    "    os.path.join(mounted_dataset_path, \"test\"),\n",
    "    shuffle=True,\n",
    "    target_size=image_size,\n",
    "    color_mode=color_mode,\n",
    "    batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(max_batches):\n",
    "    print(f\"Batch: {i}\")\n",
    "    batch = train_datagen.next()\n",
    "    x_train.extend(batch[0])\n",
    "    y_train.extend(batch[1])\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 68,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 0\n",
      "Batch: 1\n",
      "Batch: 2\n",
      "Batch: 3\n",
      "Batch: 4\n",
      "Batch: 5\n",
      "Batch: 6\n",
      "Batch: 7\n",
      "Batch: 8\n",
      "Batch: 9\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(320, 150, 150, 1)\n(320, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "source": [
    "import autokeras as ak\n",
    "\n",
    "input_node = ak.ImageInput()\n",
    "output_node = ak.Normalization()(input_node)\n",
    "output_node1 = ak.ConvBlock()(output_node)\n",
    "output_node2 = ak.ResNetBlock(version='v2')(output_node)\n",
    "output_node = ak.Merge()([output_node1, output_node2])\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "\n",
    "model = ak.AutoModel(\n",
    "    inputs=input_node, \n",
    "    outputs=output_node,\n",
    "    overwrite=True,\n",
    "    max_trials=1)\n",
    "\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2, \n",
    "    epochs=10,\n",
    "    verbose=1)\n",
    "print(model.evaluate(dataset))\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 72,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "conv_block_1/ke...|3                 |?                 \n",
      "conv_block_1/nu...|2                 |?                 \n",
      "conv_block_1/nu...|2                 |?                 \n",
      "conv_block_1/se...|True              |?                 \n",
      "conv_block_1/ma...|True              |?                 \n",
      "conv_block_1/dr...|0                 |?                 \n",
      "conv_block_1/fi...|32                |?                 \n",
      "conv_block_1/fi...|32                |?                 \n",
      "conv_block_1/fi...|32                |?                 \n",
      "conv_block_1/fi...|32                |?                 \n",
      "res_net_block_1...|False             |?                 \n",
      "res_net_block_1...|resnet50_v2       |?                 \n",
      "res_net_block_1...|False             |?                 \n",
      "classification_...|0                 |?                 \n",
      "optimizer         |adam              |?                 \n",
      "learning_rate     |0.001             |?                 \n",
      "\n",
      "Epoch 1/10\n",
      "4/8 [==============>...............] - ETA: 31s - loss: 5.4908 - accuracy: 0.4922"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-a1d3e6750cbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     max_trials=1)\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/tg2_COVIDNet/covidnet_venv/lib/python3.8/site-packages/autokeras/auto_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m             )\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         self.tuner.search(\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/tg2_COVIDNet/covidnet_venv/lib/python3.8/site-packages/autokeras/engine/tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, epochs, callbacks, validation_split, **fit_kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# Train the best model use validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/tg2_COVIDNet/covidnet_venv/lib/python3.8/site-packages/kerastuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/tg2_COVIDNet/covidnet_venv/lib/python3.8/site-packages/kerastuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'callbacks'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/tg2_COVIDNet/covidnet_venv/lib/python3.8/site-packages/autokeras/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         _, history = utils.fit_with_adaptive_batch_size(\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         )\n",
      "\u001b[0;32m~/Google Drive/tg2_COVIDNet/covidnet_venv/lib/python3.8/site-packages/autokeras/utils/utils.py\u001b[0m in \u001b[0;36mfit_with_adaptive_batch_size\u001b[0;34m(model, batch_size, **fit_kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_with_adaptive_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     history = run_with_adaptive_batch_size(\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     )\n",
      "\u001b[0;32m~/Google Drive/tg2_COVIDNet/covidnet_venv/lib/python3.8/site-packages/autokeras/utils/utils.py\u001b[0m in \u001b[0;36mrun_with_adaptive_batch_size\u001b[0;34m(batch_size, func, **fit_kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceExhaustedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/tg2_COVIDNet/covidnet_venv/lib/python3.8/site-packages/autokeras/utils/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_with_adaptive_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     history = run_with_adaptive_batch_size(\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/tg2_COVIDNet/covidnet_venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/tg2_COVIDNet/covidnet_venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/tg2_COVIDNet/covidnet_venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/tg2_COVIDNet/covidnet_venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/tg2_COVIDNet/covidnet_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/tg2_COVIDNet/covidnet_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/Google Drive/tg2_COVIDNet/covidnet_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/Google Drive/tg2_COVIDNet/covidnet_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/tg2_COVIDNet/covidnet_venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('covidnet_venv')",
   "metadata": {
    "interpreter": {
     "hash": "fb01a5cf3badac40647189a054d4d2482441cbdeb36d05fb03f9df056027b383"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}